# 项目记忆文档

## 项目概述
医学PDF结构化信息提取系统，使用Qwen3-8B模型进行文档分类和信息提取。

## 当前版本

### v7.2 生产版本 (2026-01-08)
- 适用于≤15页文档
- 成功率: 97%
- GPT-5.2评分: 9.60/10

### 方案5 v4 长文档版本 (2026-01-12)
- 适用于任意长度文档
- 成功率: 100%
- 平均覆盖率: 74.9%

## 核心架构

### v7.2 标准版本
1. **文档分类**: Qwen3-8B判断文档类型 (GUIDELINE/REVIEW/OTHER)
2. **动态Few-shot**: 根据类型加载对应的GPT-5.2预标注高质量示例
3. **结构化提取**: 提取元数据、推荐意见、关键发现、结论等

### 方案5 长文档版本
1. **智能分块**: 检测目录页、计算内容密度、识别章节标题
2. **BM25检索**: 针对不同字段使用专门关键词检索相关chunk
3. **并行提取**: 同时提取metadata、scope、findings、conclusions、recommendations
4. **字段级处理**: 每个字段独立检索最相关的内容

## 关键配置

### vLLM服务
- 模型: Qwen3-8B fp16
- 端口: 8000
- API: `http://localhost:8000/v1/chat/completions`
- **重要**: 必须设置 `"chat_template_kwargs": {"enable_thinking": False}`

### 方案5参数
- chunk_size: 4500字符
- overlap: 600字符
- top_k: 12 (检索chunk数)
- max_workers: 2 (并行度)
- timeout: 360秒

## 技术决策记录

### 为什么用fp16而不是int8?
- int8(GPTQ)在V100上速度慢14倍，成功率仅59%
- fp16性能稳定，推荐用于生产

### 为什么用动态few-shot?
- 静态few-shot(v6): 7.1分
- 动态few-shot(v7): 9.6分
- 不同文档类型结构差异大，需要针对性示例

### 方案5为什么用BM25而非向量检索?
- 无需额外embedding模型
- 医学术语匹配效果好
- 部署更简单

## 已知限制

### v7.2
1. 长文档(>15页)会被截断
2. 复杂表格提取不完整
3. 部分PDF格式错误会导致失败(约3%)

### 方案5
1. 覆盖率随文档长度下降(100+页约55%)
2. 耗时随文档长度增加
3. 部分REVIEW文档无推荐意见(正常)

## 优化历史

| 版本 | 日期 | 评分/覆盖率 | 关键改进 |
|------|------|-------------|----------|
| v4 | 01-05 | 4.1分 | 基线版本 |
| v5 | 01-06 | 6.5分 | 简化JSON结构 |
| v6 | 01-07 | 7.1分 | 静态few-shot |
| v7.1 | 01-08 | 8.98分 | 动态few-shot |
| v7.2 | 01-08 | 9.60分 | JSON解析修复 |
| 方案5 v1 | 01-12 | 12.9%覆盖 | 基础BM25检索 |
| 方案5 v2 | 01-12 | 20.1%覆盖 | 智能跳页+增强关键词 |
| 方案5 v3 | 01-12 | 24.6%覆盖 | 并行提取+二次检索 |
| 方案5 v4 | 01-12 | 74.9%覆盖 | 目录检测+Few-shot+修复 |

## 核心文件

- `production_extractor_v7.py` - 生产版本提取器
- `field_retrieval_extractor.py` - 方案5长文档提取器
- `fewshot_samples/` - Few-shot示例目录
  - `GUIDELINE_sample.json`
  - `REVIEW_sample.json`
  - `OTHER_sample.json`
