# 医学PDF提取系统部署指南

## 环境要求

### 硬件
- GPU: NVIDIA V100 16GB 或更高
- 内存: 32GB+
- 存储: 50GB+ (模型缓存)

### 软件
- Ubuntu 20.04+
- Python 3.8+
- CUDA 11.8+

## 安装步骤

### 1. 安装依赖
```bash
pip install vllm==0.13.0
pip install pymupdf
pip install requests
```

### 2. 下载模型
```bash
huggingface-cli download Qwen/Qwen3-8B --local-dir /root/autodl-tmp/hf_cache/hub/models--Qwen--Qwen3-8B
```

### 3. 启动vLLM服务
```bash
bash /root/autodl-tmp/vllm_server_v13.sh
```

### 4. 验证服务
```bash
curl http://localhost:8000/v1/models
# 应返回 {"data": [{"id": "qwen3-8b", ...}]}
```

## 使用方法

### Python调用
```python
from production_extractor_v7 import extract_pdf

result = extract_pdf("/path/to/medical.pdf")
print(f"成功: {result['success']}")
print(f"类型: {result['doc_type']}")
print(f"文档大小: {result['stats']['doc_size']}")
```

### 命令行
```bash
python production_extractor_v7.py /path/to/medical.pdf
```

## v7.6 混合策略说明

系统根据PDF页数自动选择最优提取策略：

| 文档大小 | 页数 | 策略 |
|---------|------|------|
| 短文档 | ≤15页 | 全部保留，只跳过空白页 |
| 中等文档 | 16-50页 | 跳过目录/参考文献/空白页 |
| 长文档 | >50页 | 智能选择最多50页关键内容 |

### 长文档智能选择规则
1. 保留前5页（元数据、摘要）
2. 保留最后3页（结论）
3. 优先高价值章节：摘要>结论>推荐>方法>引言
4. 按内容量填充剩余配额

## 配置参数

### vLLM服务配置
- 端口: 8000
- 模型: Qwen3-8B fp16
- 上下文长度: 16384
- GPU利用率: 0.92

### 提取器配置
| 参数 | 值 | 说明 |
|------|------|------|
| SHORT_DOC_THRESHOLD | 15 | 短文档阈值 |
| MEDIUM_DOC_THRESHOLD | 50 | 中等文档阈值 |
| max_long_doc_pages | 50 | 长文档最大选择页数 |
| min_content_chars | 100 | 空白页判断阈值 |

## 性能基准

| 指标 | v7.2 | v7.3 | v7.6 |
|------|------|------|------|
| 成功率 | 97% | 100% | 100% |
| GPT评分 | 9.60 | 9.09 | 待测 |
| 平均耗时 | 58s | 42s | ~45s |
| 长文档支持 | ❌ | ✅ | ✅ |

## 故障排查

### vLLM服务无响应
```bash
# 检查进程
ps aux | grep vllm
# 检查GPU
nvidia-smi
# 重启服务
pkill -f vllm
bash /root/autodl-tmp/vllm_server_v13.sh
```

### 提取失败
1. 检查PDF是否可读: `python -c "import fitz; fitz.open('xxx.pdf')"`
2. 检查vLLM服务: `curl http://localhost:8000/v1/models`
3. 查看错误信息: `result['error']`

## 文件结构

```
/root/pdf_summarization_deploy_20251225_093847/
├── production_extractor_v7.py    # 主提取器(v7.6)
├── fewshot_samples/              # Few-shot示例
│   ├── GUIDELINE_sample.json
│   ├── REVIEW_sample.json
│   └── OTHER_sample.json
├── memory.md                     # 项目记忆文档
├── README.md                     # 项目说明
└── 项目部署指南.md               # 本文档

/root/autodl-tmp/
├── vllm_server_v13.sh           # vLLM启动脚本
├── docs/                        # 文档备份
└── pdf_input/                   # 测试PDF
```
